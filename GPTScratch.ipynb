{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP8Nc0AYXqcrQ8+gG+HSlSx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":103,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTpjoQUprtH_","executionInfo":{"status":"ok","timestamp":1737281260822,"user_tz":-330,"elapsed":702,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"8dd8832b-ea6f-4c0c-f075-e8e5d8a31b03"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-01-19 10:07:40--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘input.txt.3’\n","\n","\rinput.txt.3           0%[                    ]       0  --.-KB/s               \rinput.txt.3         100%[===================>]   1.06M  --.-KB/s    in 0.06s   \n","\n","2025-01-19 10:07:41 (18.0 MB/s) - ‘input.txt.3’ saved [1115394/1115394]\n","\n"]}],"source":["# Tiny Shakespeare dataset\n","!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"]},{"cell_type":"code","source":["# Reat it in to inspect it\n","with open(\"input.txt\", \"r\", encoding = \"utf-8\") as f:\n","  text = f.read()"],"metadata":{"id":"Q_mavnYit8x9","executionInfo":{"status":"ok","timestamp":1737281260823,"user_tz":-330,"elapsed":23,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}}},"execution_count":104,"outputs":[]},{"cell_type":"code","source":["print(f\"Length of dataset in characters: {len(text)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"foQAzkETuJhg","executionInfo":{"status":"ok","timestamp":1737281260823,"user_tz":-330,"elapsed":23,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"b8800489-8d03-48d0-e21e-20beb8746b07"},"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of dataset in characters: 1115394\n"]}]},{"cell_type":"code","source":["# First 1000 characters\n","print(text[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nl8Dw2tmuOWs","executionInfo":{"status":"ok","timestamp":1737281260823,"user_tz":-330,"elapsed":17,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"e8b3c23c-7139-4261-ea6a-5477402a9294"},"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n","Is't a verdict?\n","\n","All:\n","No more talking on't; let it be done: away, away!\n","\n","Second Citizen:\n","One word, good citizens.\n","\n","First Citizen:\n","We are accounted poor citizens, the patricians good.\n","What authority surfeits on would relieve us: if they\n","would yield us but the superfluity, while it were\n","wholesome, we might guess they relieved us humanely;\n","but they think we are too dear: the leanness that\n","afflicts us, the object of our misery, is as an\n","inventory to particularise their abundance; our\n","sufferance is a gain to them Let us revenge this with\n","our pikes, ere we become rakes: for the gods know I\n","speak this in hunger for bread, not in thirst for revenge.\n","\n","\n"]}]},{"cell_type":"code","source":["# Unique characters that occur in this text\n","chars = sorted(list(set(text)))\n","vocab_size = len(chars)\n","print(\"\".join(chars))\n","print(vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3OfL9-geuUlD","executionInfo":{"status":"ok","timestamp":1737281260823,"user_tz":-330,"elapsed":14,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"e5347d83-871f-47b5-cb46-e8f3c785c549"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n","65\n"]}]},{"cell_type":"code","source":["# Mapping from characters to integers\n","stoi = { ch:i for i, ch in enumerate(chars)}\n","itos = { i:ch for i, ch in enumerate(chars)}\n","encode = lambda s: [stoi[c] for c in s]  # Encoder: Take the string, output a list of integer\n","decode = lambda l: \"\".join([itos[i] for i in l])  # Decoder: Take a list of integers, output a string\n","\n","#decode = lambda i: [itos[c] for c in i] Using this command will give us each alphabet as a separate string\n","\n","print(encode(\"Hii There\"))\n","print(decode(encode(\"Hii There\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CgEVt9mEu7za","executionInfo":{"status":"ok","timestamp":1737281260823,"user_tz":-330,"elapsed":10,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"109b3574-1074-404e-dad3-7080f4a8301c"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["[20, 47, 47, 1, 32, 46, 43, 56, 43]\n","Hii There\n"]}]},{"cell_type":"code","source":["# Encode the entire text dataset and store it into a torch.tensor\n","import torch\n","data = torch.tensor(encode(text), dtype = torch.long)\n","print(data.shape, data.dtype)\n","print(data[:1000])  # The 1000 characters we looked at earlier will to the GPT look like this"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBaAkm7RwjRT","executionInfo":{"status":"ok","timestamp":1737281261247,"user_tz":-330,"elapsed":431,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"1ec7555f-064b-44ea-a17b-005596c751c5"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1115394]) torch.int64\n","tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n","        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n","         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n","        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n","         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n","        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n","         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n","        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n","        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n","         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n","         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n","        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n","        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n","         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n","        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n","        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n","        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n","        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n","        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n","        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n","         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n","         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n","         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n","        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n","        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n","        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n","        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n","        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n","        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n","        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n","         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n","         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n","        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n","        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n","        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n","         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n","        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n","        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n","         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n","        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n","        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n","        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n","        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n","        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n","        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n","        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n","        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n","        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n","         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n","        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n","        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n","        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n","        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n","        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n","        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"]}]},{"cell_type":"code","source":["# Splitting the dataset into training and validation sets\n","n = int(0.9*len(data))  # First 90% will be train, rest val\n","train_data = data[:n]\n","val_data = data[n:]"],"metadata":{"id":"ph2TlYxCxedM","executionInfo":{"status":"ok","timestamp":1737281261247,"user_tz":-330,"elapsed":18,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["block_size = 8"],"metadata":{"id":"d69rEq2nyMdX","executionInfo":{"status":"ok","timestamp":1737281261248,"user_tz":-330,"elapsed":19,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["x = train_data[:block_size]\n","y = train_data[1:block_size+1]\n","for t in range(block_size):\n","  context = x[:t+1]\n","  target = y[t]\n","  print(f\"When input is {context}, the target is {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4xksdDd0uaX","executionInfo":{"status":"ok","timestamp":1737281261248,"user_tz":-330,"elapsed":18,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"20df1883-fc93-42e9-fa8b-8bd950f80b48"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["When input is tensor([18]), the target is 47\n","When input is tensor([18, 47]), the target is 56\n","When input is tensor([18, 47, 56]), the target is 57\n","When input is tensor([18, 47, 56, 57]), the target is 58\n","When input is tensor([18, 47, 56, 57, 58]), the target is 1\n","When input is tensor([18, 47, 56, 57, 58,  1]), the target is 15\n","When input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is 47\n","When input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is 58\n"]}]},{"cell_type":"code","source":["torch.manual_seed(1337)\n","batch_size = 4  # How many independent sequences will we process in parallel\n","block_size = 8  # What is the maximum context length for prediction?\n","\n","def get_batch(split):\n","  # Generate a small batch of data of inputs x and targets y\n","  data = train_data if split == \"train\" else val_data\n","  ix = torch.randint(len(data) - block_size, (batch_size,))\n","  x = torch.stack([data[i : i+block_size] for i in ix])\n","  y = torch.stack([data[i+1 : i+block_size+1] for i in ix])\n","  return x, y\n","\n","xb, yb = get_batch(\"train\")\n","print(\"Inputs:\")\n","print(xb.shape)\n","print(xb)\n","print(\"Targets:\")\n","print(yb.shape)\n","print(yb)\n","\n","print(\"-----------------------------------------------------------\")\n","\n","for b in range(batch_size):  # Batch Dimension\n","  for t in range(block_size):  # Time Dimension\n","    context = xb[b, :t+1]\n","    target = yb[b, t]\n","    print(f\"When input is {context.tolist()}, the target is {target}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ll5K4eKt1KjT","executionInfo":{"status":"ok","timestamp":1737281261248,"user_tz":-330,"elapsed":14,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"4af6ec2c-ae7c-436d-9106-0728b70781cf"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs:\n","torch.Size([4, 8])\n","tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n","        [44, 53, 56,  1, 58, 46, 39, 58],\n","        [52, 58,  1, 58, 46, 39, 58,  1],\n","        [25, 17, 27, 10,  0, 21,  1, 54]])\n","Targets:\n","torch.Size([4, 8])\n","tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n","        [53, 56,  1, 58, 46, 39, 58,  1],\n","        [58,  1, 58, 46, 39, 58,  1, 46],\n","        [17, 27, 10,  0, 21,  1, 54, 39]])\n","-----------------------------------------------------------\n","When input is [24], the target is 43\n","When input is [24, 43], the target is 58\n","When input is [24, 43, 58], the target is 5\n","When input is [24, 43, 58, 5], the target is 57\n","When input is [24, 43, 58, 5, 57], the target is 1\n","When input is [24, 43, 58, 5, 57, 1], the target is 46\n","When input is [24, 43, 58, 5, 57, 1, 46], the target is 43\n","When input is [24, 43, 58, 5, 57, 1, 46, 43], the target is 39\n","When input is [44], the target is 53\n","When input is [44, 53], the target is 56\n","When input is [44, 53, 56], the target is 1\n","When input is [44, 53, 56, 1], the target is 58\n","When input is [44, 53, 56, 1, 58], the target is 46\n","When input is [44, 53, 56, 1, 58, 46], the target is 39\n","When input is [44, 53, 56, 1, 58, 46, 39], the target is 58\n","When input is [44, 53, 56, 1, 58, 46, 39, 58], the target is 1\n","When input is [52], the target is 58\n","When input is [52, 58], the target is 1\n","When input is [52, 58, 1], the target is 58\n","When input is [52, 58, 1, 58], the target is 46\n","When input is [52, 58, 1, 58, 46], the target is 39\n","When input is [52, 58, 1, 58, 46, 39], the target is 58\n","When input is [52, 58, 1, 58, 46, 39, 58], the target is 1\n","When input is [52, 58, 1, 58, 46, 39, 58, 1], the target is 46\n","When input is [25], the target is 17\n","When input is [25, 17], the target is 27\n","When input is [25, 17, 27], the target is 10\n","When input is [25, 17, 27, 10], the target is 0\n","When input is [25, 17, 27, 10, 0], the target is 21\n","When input is [25, 17, 27, 10, 0, 21], the target is 1\n","When input is [25, 17, 27, 10, 0, 21, 1], the target is 54\n","When input is [25, 17, 27, 10, 0, 21, 1, 54], the target is 39\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","torch.manual_seed(1337)\n","\n","class BigramLanguageModel(nn.Module):\n","\n","  def __init__(self, vocab_size):\n","    super().__init__()\n","    # Each token directly reads off the logits for the next token from a lookup table\n","    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n","\n","  def forward(self, idx, targets=None):\n","\n","    # idc and targets are both (Batch, Time) tensor of integers\n","    logits = self.token_embedding_table(idx)  # (B, T, C)\n","\n","    if targets is None:\n","      loss = None\n","    else:\n","      B, T, C = logits.shape\n","      logits = logits.view(B*T, C)\n","      targets = targets.view(B*T)\n","      loss = F.cross_entropy(logits, targets)\n","\n","    return logits, loss\n","\n","  def generate(self, idx, max_new_tokens):\n","    # idc is (B, T) array of indices in the current context\n","    for _ in range(max_new_tokens):\n","      # Get the predictions\n","      logits, loss = self(idx)\n","      # Focus only on the last time step\n","      logits = logits[:, -1, :]  # becomes (B, C)\n","      # Apply softmax to get probabilities\n","      probs = F.softmax(logits, dim = -1) # (B, C)\n","      # Sampke from the distribution\n","      idx_next = torch.multinomial(probs, num_samples = 1)  # (B, 1)\n","      # Append sampled index to the running sequence\n","      idx = torch.cat((idx, idx_next), dim = 1)  # (B, T+1)\n","    return idx\n","\n","m = BigramLanguageModel(vocab_size)\n","logits, loss = m(xb, yb)\n","print(logits.shape)\n","print(loss)\n","\n","print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens = 100)[0].tolist()))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rnoqb_eb4InB","executionInfo":{"status":"ok","timestamp":1737281261248,"user_tz":-330,"elapsed":10,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"e01738bb-8d8c-43c3-842e-550f456c783e"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 65])\n","tensor(4.8786, grad_fn=<NllLossBackward0>)\n","\n","Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"]}]},{"cell_type":"code","source":["# Create a PyTorch Optimizer\n","optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)"],"metadata":{"id":"AWIohPYU-JVJ","executionInfo":{"status":"ok","timestamp":1737281261248,"user_tz":-330,"elapsed":6,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}}},"execution_count":115,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","for steps in range(10000):\n","\n","  # Sample a batch of data\n","  xb, yb = get_batch(\"train\")\n","\n","  # Evaluate the loss\n","  logits, loss = m(xb, yb)\n","  optimizer.zero_grad(set_to_none=True)\n","  loss.backward()\n","  optimizer.step()\n","\n","print(loss.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fhIu5JdZMxV-","executionInfo":{"status":"ok","timestamp":1737281281119,"user_tz":-330,"elapsed":19877,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"4f33e293-1af1-4604-9214-c6cc4a1e38c4"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["2.5727508068084717\n"]}]},{"cell_type":"code","source":["print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens = 100)[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XLXw2R5TNEXi","executionInfo":{"status":"ok","timestamp":1737281281119,"user_tz":-330,"elapsed":50,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"38684744-bcfa-4c4b-9320-4c8f4727bf28"},"execution_count":117,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Iyoteng h hasbe pave pirance\n","Rie hicomyonthar's\n","Plinseard ith henoure wounonthioneir thondy, y helti\n"]}]},{"cell_type":"code","source":["# Consider the following toy example\n","\n","torch.manual_seed(1337)\n","B, T, C = 4, 8, 2  # batch, time, channels\n","x = torch.randn(B, T, C)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D6acc4-2NLxO","executionInfo":{"status":"ok","timestamp":1737281281119,"user_tz":-330,"elapsed":46,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"d5dde169-d68c-46c9-9e9d-a9bd6431d0e7"},"execution_count":118,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 2])"]},"metadata":{},"execution_count":118}]},{"cell_type":"code","source":["# We want x[b, t] = mean_{i <= t} x [b, i]\n","xbow = torch.zeros((B, T, C))\n","for b in range(B):\n","  for t in range(T):\n","    xprev = x[b, :t+1]  # (t, C)\n","    xbow[b, t] = torch.mean(xprev, 0)"],"metadata":{"id":"CaHwr_c1SCuj","executionInfo":{"status":"ok","timestamp":1737281281119,"user_tz":-330,"elapsed":43,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}}},"execution_count":119,"outputs":[]},{"cell_type":"code","source":["# Version 2\n","\n","wei = torch.tril(torch.ones(T, T))\n","wei = wei / wei.sum(1, keepdim = True)\n","\n","xbow2 = wei @ x  # (B, T, T) @ (B, T, C) -----> (B, T, C)\n","torch.allclose(xbow, xbow2, atol = 1e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPSOGG6OSS1J","executionInfo":{"status":"ok","timestamp":1737281281120,"user_tz":-330,"elapsed":44,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"73b78388-e276-427c-fa00-765f4abb7faa"},"execution_count":120,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":120}]},{"cell_type":"code","source":["# Version 3: Use Softmax\n","\n","tril = torch.tril(torch.ones(T, T))\n","wei = torch.zeros((T, T))\n","wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n","wei = F.softmax(wei, dim = -1)\n","xbow3 = wei @ x\n","torch.allclose(xbow, xbow3, atol = 1e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jexRZLZq_IcN","executionInfo":{"status":"ok","timestamp":1737281281120,"user_tz":-330,"elapsed":36,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"4bf9e6ee-9c30-420e-e4f0-81753d2b8428"},"execution_count":121,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":121}]},{"cell_type":"code","source":["torch.tril(torch.ones(3, 3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJ4VQa6ESawO","executionInfo":{"status":"ok","timestamp":1737281281120,"user_tz":-330,"elapsed":30,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"323cee5a-2644-486e-e89c-bc4b591f0c2e"},"execution_count":122,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0.],\n","        [1., 1., 0.],\n","        [1., 1., 1.]])"]},"metadata":{},"execution_count":122}]},{"cell_type":"code","source":["torch.manual_seed(42)\n","a = torch.tril(torch.ones(3, 3))\n","a = a / torch.sum(a, 1, keepdim = True)\n","b = torch.randint(0, 10, (3, 2)).float()\n","c = a @ b\n","\n","print(\"a = \")\n","print(a)\n","print(\"--\")\n","print(\"b = \")\n","print(b)\n","print(\"--\")\n","print(\"c = \")\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Haz-AZqGSuE3","executionInfo":{"status":"ok","timestamp":1737281281121,"user_tz":-330,"elapsed":28,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"970740da-9c12-44a2-ef6a-324bc99aba2b"},"execution_count":123,"outputs":[{"output_type":"stream","name":"stdout","text":["a = \n","tensor([[1.0000, 0.0000, 0.0000],\n","        [0.5000, 0.5000, 0.0000],\n","        [0.3333, 0.3333, 0.3333]])\n","--\n","b = \n","tensor([[2., 7.],\n","        [6., 4.],\n","        [6., 5.]])\n","--\n","c = \n","tensor([[2.0000, 7.0000],\n","        [4.0000, 5.5000],\n","        [4.6667, 5.3333]])\n"]}]},{"cell_type":"code","source":["# Version 4: Self-Attention\n","torch.manual_seed(1337)\n","B, T, C = 4, 8, 32  # Batch, Time, Channels\n","x = torch.randn(B, T, C)\n","\n","# Let's see a single head perform self-attention\n","head_size = 16\n","key = nn.Linear(C, head_size, bias = False)\n","query = nn.Linear(C, head_size, bias = False)\n","value = nn.Linear(C, head_size, bias = False)\n","\n","k = key(x)   # (B, T, 16)\n","q = query(x) # (B, T, 16)\n","\n","wei = q @ k.transpose(-2, -1) * head_size**-0.5  # (B, T, 16) @ (B, T, 16) ---> (B, T, T)\n","\n","tril = torch.tril(torch.ones(T, T))\n","# wei = torch.zeros((T, T))\n","wei = wei.masked_fill(tril == 0, float(\"-inf\"))\n","wei = F.softmax(wei, dim = -1)\n","\n","v = value(x)\n","out = wei @ v\n","#out = wei @ x\n","\n","out.shape"],"metadata":{"id":"CARbfX75TC9O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1737285568276,"user_tz":-330,"elapsed":683,"user":{"displayName":"Priangshu Paul","userId":"13565368205818094014"}},"outputId":"67127ea9-6250-415c-9c09-04cd09b277f2"},"execution_count":130,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 8, 16])"]},"metadata":{},"execution_count":130}]},{"cell_type":"code","source":[],"metadata":{"id":"0rynkB0XO_qr"},"execution_count":null,"outputs":[]}]}